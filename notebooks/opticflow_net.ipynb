{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "torch.manual_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optic(img1, img2):\n",
    "    if img1 is None or img2 is None:\n",
    "        print(\"no files\")\n",
    "        return None\n",
    "\n",
    "    img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if img1_gray.shape != img2_gray.shape:\n",
    "        img2_gray = cv2.resize(img2_gray, (img1_gray.shape[1], img1_gray.shape[0]))\n",
    "\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(img1_gray, img2_gray, None, 0.5, 3, 19, 5, 7, 1.2, 0)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv = np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)\n",
    "    hsv[..., 0] = angle * 180 / np.pi / 2\n",
    "    hsv[..., 1] = 255 \n",
    "    hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    flow_bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return flow_bgr\n",
    "\n",
    "\n",
    "class SiameseDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_root_folder, transform=None):\n",
    "\n",
    "        self.data = []\n",
    "        self.image_root_folder = image_root_folder\n",
    "        self.transform = transform\n",
    "        self.emotion_to_group = {\n",
    "            \"happiness\": \"positive\",\n",
    "            \"disgust\": \"negative\",\n",
    "            \"fear\": \"negative\",\n",
    "            \"surprise\": \"surprise\",\n",
    "            \"repression\": \"negative\",\n",
    "            \"sadness\": \"negative\",\n",
    "            \"others\": \"other\"\n",
    "        }\n",
    "\n",
    "\n",
    "        all_groups = set(self.emotion_to_group.values())\n",
    "        self.group_to_index = {group: idx for idx, group in enumerate(sorted(all_groups))}\n",
    "\n",
    "        with open(csv_file, 'r') as f:\n",
    "            next(f)  \n",
    "            for line in f.readlines():\n",
    "                _, subject, folder, onset_frame, apex_frame, emotion = line.strip().split(',')\n",
    "                self.data.append({\n",
    "                    'subject': subject,\n",
    "                    'folder': folder,\n",
    "                    'onset_frame': int(onset_frame),\n",
    "                    'apex_frame': int(apex_frame),\n",
    "                    'emotion': emotion\n",
    "                })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.data[idx]\n",
    "        folder_path = os.path.join(self.image_root_folder, f\"sub{str(entry['subject']).zfill(2)}\", f\"ROI_{entry['folder']}\")\n",
    "\n",
    "        image1_path = os.path.join(folder_path, f\"img{entry['onset_frame']}.jpg\")\n",
    "        image2_path = os.path.join(folder_path, f\"img{entry['apex_frame']}.jpg\")\n",
    "\n",
    "        image1 = Image.open(image1_path).convert(\"RGB\") \n",
    "        image2 = Image.open(image2_path).convert(\"RGB\") \n",
    "\n",
    "        img1_np = np.array(image1)\n",
    "        img2_np = np.array(image2)\n",
    "\n",
    "\n",
    "        optic_flow = create_optic(img1_np, img2_np)\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "            image2 = self.transform(image2)\n",
    "            optic_flow = self.transform(Image.fromarray(optic_flow))\n",
    "\n",
    "\n",
    "        emotion_label = entry['emotion']\n",
    "        group_label = self.emotion_to_group[emotion_label]\n",
    "        label_tensor = torch.tensor(self.group_to_index[group_label], dtype=torch.long)\n",
    "        return optic_flow, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OpticalFlowResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate=0.2):\n",
    "        super(OpticalFlowResNetClassifier, self).__init__()\n",
    "        \n",
    "        # Backbone: ResNet (with pre-trained weights)\n",
    "        resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "        # Optionally freeze ResNet parameters\n",
    "        # for param in resnet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.backbone = nn.Sequential(*list(resnet.children())[:-1]) \n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(512, 256),  \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),  \n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(64, num_classes) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.backbone(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.embedding(x)\n",
    "        predictions = self.classifier(x)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25\n",
    "patience = 6\n",
    "batch_size = 10\n",
    "learning_rate = 0.0001\n",
    "\n",
    "dataset = SiameseDataset(csv_file=\"../info.csv\", image_root_folder=\"../output_copy\", transform=transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize(mean = [0.5], std = [0.5])\n",
    "]))\n",
    "\n",
    "\n",
    "train_size = int(0.75 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = OpticalFlowResNetClassifier(num_classes=4,dropout_rate=0.5).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "best_val_loss = float('inf') \n",
    "early_stop_counter = 0  \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        optic, labels = batch\n",
    "        optic, labels = optic.to(device),labels.to(device).long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions= model(optic)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "\n",
    "    model.eval()  \n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input1, labels = batch\n",
    "            input1, labels = input1.to(device), labels.to(device).long()\n",
    "\n",
    "            predictions= model(input1)\n",
    "            loss = criterion(predictions, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        early_stop_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_optic_model.pth\")\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"opticflow_model.pth\"))\n",
    "\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()  \n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad(): \n",
    "        for batch in val_loader:\n",
    "            input1, labels = batch\n",
    "            input1, labels = input1.to(device), labels.to(device)\n",
    "\n",
    "            predictions = model(input1)\n",
    "            probabilities = F.softmax(predictions, dim=1)\n",
    "            predicted_classes = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_predictions, average='weighted')\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "\n",
    "    results = {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "results = evaluate_model(model, val_loader, device)\n",
    "print(\"Accuracy:\", results['accuracy'])\n",
    "print(\"Precision:\", results['precision'])\n",
    "print(\"Recall:\", results['recall'])\n",
    "print(\"F1 Score:\", results['f1_score'])\n",
    "print(\"Confusion Matrix:\\n\", results['confusion_matrix'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
